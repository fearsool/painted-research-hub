import requests
import json

# --- AYARLAR ---
target_domain = "paintedresearch.org"

def deep_scan(domain):
    print(f"ğŸ” {domain} iÃ§in derin tarama baÅŸlatÄ±lÄ±yor...")
    # Wayback Machine CDX API'sine doÄŸrudan istek atÄ±yoruz
    cdx_url = f"http://web.archive.org/cdx/search/cdx?url={domain}/*&output=json&collapse=urlkey&fl=original"
    
    try:
        response = requests.get(cdx_url, timeout=15)
        if response.status_code == 200:
            results = response.json()
            # Ä°lk satÄ±r baÅŸlÄ±k olduÄŸu iÃ§in [1:] ile baÅŸlÄ±yoruz
            urls = [row[0] for row in results[1:]]
            return urls
        else:
            return []
    except Exception as e:
        print(f"âŒ Hata oluÅŸtu: {e}")
        return []

print("ğŸš€ ArÅŸiv Kurtarma Operasyonu: Mod 2 (Derin Tarama)")
found_urls = deep_scan(target_domain)

if found_urls:
    # Gereksiz dosyalarÄ± (resim, css vb.) temizleyelim
    cleaned_urls = [u for u in found_urls if not any(ext in u.lower() for ext in ['.jpg', '.png', '.css', '.js', '.pdf', '.gif'])]
    
    print(f"\nâœ… Toplam {len(cleaned_urls)} adet potansiyel iÃ§erik sayfasÄ± bulundu:")
    with open("kurtarilan_veriler.txt", "w", encoding="utf-8") as f:
        for url in cleaned_urls:
            print(f"ğŸ”— {url}")
            f.write(f"{url}\n")
    print("\nğŸ“ Liste 'kurtarilan_veriler.txt' dosyasÄ±na kaydedildi.")
else:
    print("âŒ Maalesef bu domain iÃ§in ulaÅŸÄ±labilir bir URL yapÄ±sÄ± bulunamadÄ±.")